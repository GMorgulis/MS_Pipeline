{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6db63270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nget_one_set_one_Xscore(set, model, scaler) -> list of scores \\n\\nget_one_set_one_Pscore(set, model, scaler) -> list of scores\\n\\nget_one_set_all_scores(set) -> 2d list of scores (models labeled) and totals\\n\\nget_all_sets_all_scores -> above method but for all sets \\n\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "get_one_set_one_Xscore(set, model, scaler) -> list of scores \n",
    "\n",
    "get_one_set_one_Pscore(set, model, scaler) -> list of scores\n",
    "\n",
    "get_one_set_all_scores(set) -> 2d list of scores (models labeled) and totals\n",
    "\n",
    "get_all_sets_all_scores -> above method but for all sets \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8e8f313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import colorsys\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6a9a7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DeeperNLCModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        dropout_rate = 0.5\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 16),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(16, 8),\n",
    "            nn.BatchNorm1d(8),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(8, 4),\n",
    "            nn.BatchNorm1d(4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(4, 1)  # Final output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce_loss = self.bce(input, target)\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        focal = self.alpha * (1 - pt) ** self.gamma * bce_loss\n",
    "        return focal.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1494bbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_from_csv(set_path):\n",
    "    X = pd.read_csv(set_path)\n",
    "    ids = X['id']\n",
    "    X = X.drop(columns=['id', 'is_centrosymmetric', \"crystal_system\"])\n",
    "    X = X.values\n",
    "    return X, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9a6ee5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(scaler_path, X):\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    X = scaler.transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7ca12884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_xgb(model_path, X):\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.load_model(model_path)\n",
    "    probs = model.predict_proba(X)[:, 1]\n",
    "    score = np.zeros_like(probs, dtype=int)\n",
    "\n",
    "    thresholds = np.round(np.arange(0.30, 1.00, 0.01), 2)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        score += (probs >= threshold).astype(int)\n",
    "    print(f\"{model_path}: Done scoring\")\n",
    "\n",
    "    return score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8dc9070e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_with_torch(model_path, X):\n",
    "    input_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "    #model = torch.load(model_path, weights_only=False)\n",
    "    model = DeeperNLCModel(296)  # replace with actual feature count\n",
    "    # Load the state dict\n",
    "    state_dict = torch.load(model_path)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "\n",
    "    # If output is logits, convert to probabilities\n",
    "    if outputs.shape[1] == 1:\n",
    "        probs = torch.sigmoid(outputs).squeeze().numpy()  # shape: (n_samples,)\n",
    "    else:\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1].numpy()  # shape: (n_samples,)\n",
    "\n",
    "    thresholds = np.round(np.arange(0.30, 1.00, 0.01), 2)\n",
    "\n",
    "    # Apply thresholds to compute scores\n",
    "    score = np.zeros_like(probs, dtype=int)\n",
    "    for threshold in thresholds:\n",
    "        score += (probs >= threshold).astype(int)\n",
    "\n",
    "    print(f\"{model_path}: Done scoring\")\n",
    "    return(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b531b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xgb_ensemble(set_path):\n",
    "    X, ids = input_from_csv(set_path)\n",
    "    model_paths = glob.glob(\"models/x*\")\n",
    "    scaler_paths = glob.glob(\"scalers/x*\")\n",
    "    print(len(model_paths), len(scaler_paths))\n",
    "    model_scores = []\n",
    "\n",
    "    for i in range(len(model_paths)):\n",
    "        X = scale(scaler_paths[i], X)\n",
    "        score = score_with_xgb(model_paths[i], X)\n",
    "        print(np.argmax(score))\n",
    "        model_scores.append(score)\n",
    "\n",
    "    scores_df = pd.DataFrame(model_scores).T\n",
    "    scores_df.columns = [f\"model_{i}_score\" for i in range(len(model_scores))]\n",
    "    scores_df[\"total_score\"] = scores_df.sum(axis=1)\n",
    "    scores_df.insert(0, \"id\", ids.values)\n",
    "\n",
    "    # Save\n",
    "    scores_df.to_csv(\"xgb_scores.csv\", index=False)\n",
    "    print(\"Saved threshold_scores.csv with per-model and total scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87cab6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_ensemble(set_path):\n",
    "    X, ids = input_from_csv(set_path)\n",
    "    model_paths = glob.glob(\"models/t*\")\n",
    "    scaler_paths = glob.glob(\"scalers/t*\")\n",
    "    print(len(model_paths), len(scaler_paths))\n",
    "    model_scores = []\n",
    "\n",
    "    for i in range(len(model_paths)):\n",
    "        X = scale(scaler_paths[i], X)\n",
    "        score = score_with_torch(model_paths[i], X)\n",
    "        print(model_paths[i], scaler_paths[i])\n",
    "        model_scores.append(score)\n",
    "\n",
    "    scores_df = pd.DataFrame(model_scores).T\n",
    "    scores_df.columns = [f\"model_{i}_score\" for i in range(len(model_scores))]\n",
    "    scores_df[\"total_score\"] = scores_df.sum(axis=1)\n",
    "    scores_df.insert(0, \"id\", ids.values)\n",
    "\n",
    "    # Save\n",
    "    scores_df.to_csv(\"torch_scores.csv\", index=False)\n",
    "    print(\"Saved threshold_scores.csv with per-model and total scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760ccd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "models\\x0.json: Done scoring\n",
      "1512\n",
      "models\\x1.json: Done scoring\n",
      "2393\n",
      "models\\x2.json: Done scoring\n",
      "0\n",
      "models\\x3.json: Done scoring\n",
      "458\n",
      "models\\x4.json: Done scoring\n",
      "164\n",
      "models\\x5.json: Done scoring\n",
      "3442\n",
      "models\\x6.json: Done scoring\n",
      "1664\n",
      "models\\x7.json: Done scoring\n",
      "2561\n",
      "models\\x8.json: Done scoring\n",
      "796\n",
      "models\\x9.json: Done scoring\n",
      "0\n",
      "Saved threshold_scores.csv with per-model and total scores.\n",
      "10 10\n",
      "models\\t0.pt: Done scoring\n",
      "models\\t0.pt scalers\\t0.pkl\n",
      "models\\t1.pt: Done scoring\n",
      "models\\t1.pt scalers\\t1.pkl\n",
      "models\\t2.pt: Done scoring\n",
      "models\\t2.pt scalers\\t2.pkl\n",
      "models\\t3.pt: Done scoring\n",
      "models\\t3.pt scalers\\t3.pkl\n",
      "models\\t4.pt: Done scoring\n",
      "models\\t4.pt scalers\\t4.pkl\n",
      "models\\t5.pt: Done scoring\n",
      "models\\t5.pt scalers\\t5.pkl\n",
      "models\\t6.pt: Done scoring\n",
      "models\\t6.pt scalers\\t6.pkl\n",
      "models\\t7.pt: Done scoring\n",
      "models\\t7.pt scalers\\t7.pkl\n",
      "models\\t8.pt: Done scoring\n",
      "models\\t8.pt scalers\\t8.pkl\n",
      "models\\t9.pt: Done scoring\n",
      "models\\t9.pt scalers\\t9.pkl\n",
      "Saved threshold_scores.csv with per-model and total scores.\n"
     ]
    }
   ],
   "source": [
    "path = 'data/Set_11/featurized_materials.csv'\n",
    "get_xgb_ensemble(path)\n",
    "get_torch_ensemble(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e7c211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Highest Scoring Materials (XGBoost):\n",
      "              id  total_score\n",
      "426    mp-561472          185\n",
      "1894   mp-643099          184\n",
      "2396   mp-866713          183\n",
      "7175  mp-1193600          183\n",
      "7153  mp-1182214          181\n",
      "7618   mp-684725          181\n",
      "5953  mp-2232217          176\n",
      "2566  mp-1199165          176\n",
      "5909  mp-2229444          175\n",
      "4828  mp-1176743          175\n",
      "7170  mp-1192990          174\n",
      "4807  mp-1238368          174\n",
      "2768  mp-1212522          173\n",
      "4294  mp-1233347          171\n",
      "4984   mp-696931          170\n",
      "2422  mp-1251539          170\n",
      "1512  mp-2210626          169\n",
      "4315  mp-1233464          167\n",
      "3093   mp-755030          167\n",
      "6619   mp-583429          166\n"
     ]
    }
   ],
   "source": [
    "xgb_scores_df = pd.read_csv(\"xgb_scores.csv\")\n",
    "\n",
    "# Sort by total_score in descending order and take top 10\n",
    "top10_xgb = xgb_scores_df.sort_values(by=\"total_score\", ascending=False).head(20)\n",
    "\n",
    "# Print only ID and total score\n",
    "print(\"Top 10 Highest Scoring Materials (XGBoost):\")\n",
    "print(top10_xgb[[\"id\", \"total_score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "962b79dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Highest Scoring Materials:\n",
      "              id  total_score\n",
      "2238   mp-542807          174\n",
      "4300  mp-1233394          172\n",
      "2768  mp-1212522          171\n",
      "1252  mp-1219288          165\n",
      "5520  mp-1235328          163\n",
      "677   mp-1228774          160\n",
      "6483  mp-1219405          156\n",
      "4271  mp-1233222          155\n",
      "5581  mp-1236046          154\n",
      "692   mp-1229021          153\n",
      "453   mp-1045011          151\n",
      "4281  mp-1233289          149\n",
      "4308  mp-1233439          149\n",
      "4336  mp-1233587          145\n",
      "528   mp-1219471          143\n",
      "2876  mp-1226966          142\n",
      "694   mp-1229079          142\n",
      "7409  mp-2715263          141\n",
      "4663   mp-807421          140\n",
      "6509  mp-1228323          139\n"
     ]
    }
   ],
   "source": [
    "scores_df = pd.read_csv(\"torch_scores.csv\")\n",
    "\n",
    "# Sort by total_score descending and select top 10\n",
    "top10 = scores_df.sort_values(by=\"total_score\", ascending=False).head(20)\n",
    "\n",
    "# Print the results\n",
    "print(\"Top 10 Highest Scoring Materials:\")\n",
    "print(top10[[\"id\", \"total_score\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "311bfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "torch_df = pd.read_csv(\"torch_scores.csv\")\n",
    "xgb_df = pd.read_csv(\"xgb_scores.csv\")\n",
    "\n",
    "# Extract id and last column (total score) from each\n",
    "torch_scores = torch_df.iloc[:, [0, -1]].copy()\n",
    "xgb_scores = xgb_df.iloc[:, [0, -1]].copy()\n",
    "\n",
    "# Rename columns\n",
    "torch_scores.columns = ['id', 'torch_score']\n",
    "xgb_scores.columns = ['id', 'xgb_score']\n",
    "\n",
    "# Merge on id\n",
    "combined_df = pd.merge(torch_scores, xgb_scores, on='id', how='inner')\n",
    "\n",
    "# Create total_score column as sum of torch and xgb scores\n",
    "combined_df['total_score'] = combined_df['torch_score'] + combined_df['xgb_score']\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv(\"combined_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a3770623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  torch_score  xgb_score  total_score\n",
      "2768  mp-1212522          171        173          344\n",
      "2238   mp-542807          174        164          338\n",
      "4300  mp-1233394          172        147          319\n",
      "5520  mp-1235328          163        150          313\n",
      "4271  mp-1233222          155        143          298\n",
      "4336  mp-1233587          145        147          292\n",
      "2396   mp-866713          107        183          290\n",
      "2876  mp-1226966          142        147          289\n",
      "2239   mp-581276          120        164          284\n",
      "5581  mp-1236046          154        130          284\n"
     ]
    }
   ],
   "source": [
    "top_ten = combined_df.sort_values(by='total_score', ascending=False).head(10)\n",
    "\n",
    "print(top_ten)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
